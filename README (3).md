# Bias Mitigation in Large Language Models (LLaMA-3.1 + BBQ Benchmark)

This repository investigates social bias in Large Language Models using the BBQ benchmark.  
It provides a fully reproducible pipeline including data loading, baseline evaluation, Counterfactual Data Augmentation (CDA), QLoRA fineâ€‘tuning, Fewâ€‘Shot prompting, and structured fairness evaluation (sDIS, sAMB, AURC, logâ€‘odds).

---

## ğŸ“Œ Project Overview

Large Language Models (LLMs) can unintentionally propagate or amplify social biases.  
This project evaluates bias in LLaMAâ€‘3.1â€‘8Bâ€‘Instruct and explores two mitigation strategies:

1. **Counterfactual Data Augmentation (CDA)**  
2. **Fewâ€‘Shot Prompting with Debiasingâ€‘Pattern Examples**  

All methods are evaluated on the **BBQ Benchmark**, covering nine sensitive categories.

---

## ğŸ“‚ Repository Structure

```
bias-llm-fairness/
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ environment.yml
â”œâ”€â”€ LICENSE
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ processed/
â”‚   â””â”€â”€ counterfactual/
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 1-load-clean-eda.ipynb
â”‚   â”œâ”€â”€ 2-baseline-model.ipynb
â”‚   â”œâ”€â”€ 3-method-1-cda.ipynb
â”‚   â”œâ”€â”€ 4-method-2-few-shot.ipynb
â”‚   â”œâ”€â”€ 5-evaluation.ipynb
â”‚   â””â”€â”€ figures/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_loader.py
â”‚   â”œâ”€â”€ preprocess.py
â”‚   â”œâ”€â”€ cda.py
â”‚   â”œâ”€â”€ model_baseline.py
â”‚   â”œâ”€â”€ train_qlora.py
â”‚   â”œâ”€â”€ few_shot.py
â”‚   â”œâ”€â”€ evaluation.py
â”‚   â””â”€â”€ utils.py
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ baseline/
â”‚   â”œâ”€â”€ cda_qlora/
â”‚   â”œâ”€â”€ few_shot/
â”‚   â””â”€â”€ summary.csv
â”‚
â””â”€â”€ report/
    â”œâ”€â”€ Bias_Mitigation_Report.pdf
    â””â”€â”€ references.bib
```

---

## ğŸš€ Methods Implemented

### **1. Baseline Model Evaluation**
- LLaMAâ€‘3.1â€‘8Bâ€‘Instruct evaluated directly on BBQ.
- Analysis of:
  - Ambiguous vs. nonâ€‘ambiguous cases  
  - Target vs. nonâ€‘target bias  
  - Incorrect inference patterns  

### **2. Counterfactual Data Augmentation (CDA)**
- Identity-swapping via lexical templates  
- Augments dataset size and balances sensitive attributes  
- QLoRA used for parameterâ€‘efficient fineâ€‘tuning  

### **3. Fewâ€‘Shot Debiasing**
- Manual construction of balanced exemplars  
- Introduces reasoning patterns for fairer inference  

---

## ğŸ“Š Evaluation Metrics

| Metric | Description |
|-------|-------------|
| **sDIS** | Measures directional bias across demographic dimensions |
| **sAMB** | Measures ambiguous-case bias tendencies |
| **AURC** | Area under the rejection curve (confidence calibration) |
| **Log-Odds Ratio** | Bias magnitude across identity pairs |

All metrics follow the definitions from the BBQ benchmark paper.

---

## ğŸ§ª How to Run the Project

### **1. Install environment**
```bash
conda env create -f environment.yml
conda activate llm-bias
```

### **2. Download the BBQ dataset**
Place files into:
```
data/raw/
```

### **3. Run preprocessing**
```bash
python src/preprocess.py
```

### **4. Run baseline inference**
```bash
python src/model_baseline.py
```

### **5. Run CDA + QLoRA training**
```bash
python src/train_qlora.py
```

### **6. Run Fewâ€‘Shot prompting experiments**
```bash
python src/few_shot.py
```

### **7. Evaluate**
```bash
python src/evaluation.py
```

---

## ğŸ“ˆ Results Summary (High-Level)

| Method | sDIS â†“ | sAMB â†“ | AURC â†‘ | Notes |
|--------|--------|--------|--------|--------|
| Baseline | High bias | High | Low | Clear preference for societal stereotypes |
| CDA + QLoRA | Reduced | Reduced | Improved | Strongest overall mitigation |
| Fewâ€‘Shot | Moderate reduction | Low | Stable | Effective without training |

(Insert your actual numbers here.)

---

## ğŸ§± Dependencies

- Python 3.10+
- Hugging Face Transformers
- PEFT (QLoRA)
- PyTorch
- NumPy, Pandas
- matplotlib, seaborn
- tqdm
- scikitâ€‘learn

Full list in **environment.yml**.

---

## ğŸ“˜ Report

The full academic reportâ€”including methodology, metric definitions, diagrams, and result discussionâ€”is available in:

```
report/Bias_Mitigation_Report.pdf
```

---

## ğŸ“„ License

MIT License (or your chosen license).

---

## ğŸ¤ Acknowledgements
- BBQ Benchmark authors  
- Meta LLaMAâ€‘3.1  
- Hugging Face ecosystem  
- University of Sydney â€” Advanced Machine Learning Coursework

---

## â­ If you use this work
Please cite or link to this repository.

---
